{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "      <th>Event</th>\n",
       "      <th>Activities</th>\n",
       "      <th>Related Component</th>\n",
       "      <th>Action/Cause</th>\n",
       "      <th>Interal/External</th>\n",
       "      <th>Shutdown Details</th>\n",
       "      <th>Startup Details</th>\n",
       "      <th>Supplied Grid after Action</th>\n",
       "      <th>Shutdown Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-22 20:13:00</td>\n",
       "      <td>2023-05-22 20:32:00</td>\n",
       "      <td>LGS#1 Trip by 86N energized</td>\n",
       "      <td>Mechanical</td>\n",
       "      <td>TGB Oil Level</td>\n",
       "      <td>Repairment</td>\n",
       "      <td>Internal</td>\n",
       "      <td>Trip by 86 N Alarm</td>\n",
       "      <td>Flying Started</td>\n",
       "      <td>FCE Grid</td>\n",
       "      <td>Unplanned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-26 10:07:00</td>\n",
       "      <td>2022-03-26 13:50:00</td>\n",
       "      <td>LGS#1 Trip by 86N energized</td>\n",
       "      <td>Mechanical</td>\n",
       "      <td>Rotor Shaft Current at Lower Generator</td>\n",
       "      <td>Repairment</td>\n",
       "      <td>Internal</td>\n",
       "      <td>Trip by 86N Alarm to Standstill</td>\n",
       "      <td>Start via 4/CS</td>\n",
       "      <td>FCE Grid</td>\n",
       "      <td>Unplanned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-28 06:15:00</td>\n",
       "      <td>2021-05-30 00:58:00</td>\n",
       "      <td>LGS#1 Trip by 86N energized</td>\n",
       "      <td>Mechanical</td>\n",
       "      <td>TGB Cooling Water</td>\n",
       "      <td>Repairment</td>\n",
       "      <td>Internal</td>\n",
       "      <td>Trip by 86N Alarm</td>\n",
       "      <td>Started via 4/CS</td>\n",
       "      <td>FCE Grid</td>\n",
       "      <td>Unplanned</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Start Time            End Time                        Event  \\\n",
       "0 2023-05-22 20:13:00 2023-05-22 20:32:00  LGS#1 Trip by 86N energized   \n",
       "1 2022-03-26 10:07:00 2022-03-26 13:50:00  LGS#1 Trip by 86N energized   \n",
       "3 2021-05-28 06:15:00 2021-05-30 00:58:00  LGS#1 Trip by 86N energized   \n",
       "\n",
       "   Activities                       Related Component Action/Cause  \\\n",
       "0  Mechanical                           TGB Oil Level   Repairment   \n",
       "1  Mechanical  Rotor Shaft Current at Lower Generator   Repairment   \n",
       "3  Mechanical                       TGB Cooling Water   Repairment   \n",
       "\n",
       "  Interal/External                 Shutdown Details   Startup Details  \\\n",
       "0         Internal               Trip by 86 N Alarm    Flying Started   \n",
       "1         Internal  Trip by 86N Alarm to Standstill    Start via 4/CS   \n",
       "3         Internal                Trip by 86N Alarm  Started via 4/CS   \n",
       "\n",
       "  Supplied Grid after Action Shutdown Type  \n",
       "0                   FCE Grid     Unplanned  \n",
       "1                   FCE Grid     Unplanned  \n",
       "3                   FCE Grid     Unplanned  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from src.models import *\n",
    "from src.constants import *\n",
    "from src.plotting import *\n",
    "from src.pot import *\n",
    "from src.utils import *\n",
    "from src.diagnosis import *\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "from datetime import datetime, timedelta\n",
    "from main import  load_dataset, backprop\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"text.usetex\"] = False\n",
    "plt.rcParams['figure.figsize'] = 8, 5\n",
    "\n",
    "def normalize3(a, min_a=None, max_a=None):\n",
    "    if min_a is None: min_a, max_a = np.min(a, axis=0), np.max(a, axis=0)\n",
    "    return ((a - min_a) / (max_a - min_a + 0.0001)), min_a, max_a\n",
    "\n",
    "def convert_to_windows(data, model):\n",
    "    windows = []\n",
    "    w_size = model.n_window\n",
    "    for i, g in enumerate(data):\n",
    "        if i >= w_size:\n",
    "            w = data[i - w_size:i]  # cut\n",
    "        else:\n",
    "            w = torch.cat([data[0].repeat(w_size - i, 1), data[0:i]])  # pad\n",
    "        windows.append(w if 'DTAAD' in model.name or 'Attention' in model.name or 'TranAD' in model.name else w.view(-1))\n",
    "    return torch.stack(windows)\n",
    "\n",
    "def load_model(modelname, dims):\n",
    "    import src.models\n",
    "    model_class = getattr(src.models, modelname)\n",
    "    model = model_class(dims).double()\n",
    "    fname = f'checkpoints/{modelname}_{args.dataset}/model.ckpt'\n",
    "    if os.path.exists(fname) and (not args.retrain or args.test):\n",
    "        checkpoint = torch.load(fname, weights_only=False)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        print(f\"{color.GREEN}Creating new model: {model.name}{color.ENDC}\")\n",
    "        assert True\n",
    "    return model\n",
    "\n",
    "def filter_noise_es(df, alpha=0.4, reduction=False):\n",
    "    import copy\n",
    "    new_df = copy.deepcopy(df)\n",
    "    \n",
    "    for column in df:\n",
    "        new_df[column] = df[column].ewm(alpha=alpha, adjust=False).mean()\n",
    "    \n",
    "    if reduction:\n",
    "        return new_df[::len(df)]  # Adjust sparsity if needed\n",
    "    else:\n",
    "        return new_df\n",
    "\n",
    "def wgn_pandas(df_withtime, snr, alpha=0.15, window_size=120):\n",
    "    df_no_timestamp = df_withtime.drop(columns=['TimeStamp'])\n",
    "    noisy_df = pd.DataFrame(index=df_no_timestamp.index, columns=df_no_timestamp.columns)\n",
    "\n",
    "    for start in range(0, len(df_no_timestamp), window_size):\n",
    "        window = df_no_timestamp.iloc[start:start + window_size]\n",
    "        \n",
    "        min_window, max_window = window.min(), window.max()\n",
    "        #x = (window - min_window) / (max_window - min_window + 1e-4)\n",
    "        Ps = np.sum(np.power(window, 2), axis=0) / len(window)\n",
    "        Pn = Ps / (np.power(10, snr / 10))\n",
    "\n",
    "        noise = np.random.randn(*window.shape) * np.sqrt(Pn.values)\n",
    "        noisy_window = window + (noise / 100)\n",
    "\n",
    "        noisy_df.iloc[start:start + window_size] = noisy_window\n",
    "    \n",
    "    noisy_df.reset_index(drop=True, inplace=True)\n",
    "    noisy_df = filter_noise_es(pd.DataFrame(noisy_df, columns=noisy_df.columns), alpha)\n",
    "\n",
    "    df_timestamp = df_withtime['TimeStamp']\n",
    "    df_timestamp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df_withtime = pd.concat([df_timestamp, noisy_df], axis=1)\n",
    "    return df_withtime\n",
    "\n",
    "feature_set = ['Active Power', 'Reactive Power', 'Governor speed actual', 'UGB X displacement', 'UGB Y displacement',\n",
    "    'LGB X displacement', 'LGB Y displacement', 'TGB X displacement',\n",
    "    'TGB Y displacement', 'Stator winding temperature 13',\n",
    "    'Stator winding temperature 14', 'Stator winding temperature 15',\n",
    "    'Surface Air Cooler Air Outlet Temperature',\n",
    "    'Surface Air Cooler Water Inlet Temperature',\n",
    "    'Surface Air Cooler Water Outlet Temperature',\n",
    "    'Stator core temperature', 'UGB metal temperature',\n",
    "    'LGB metal temperature 1', 'LGB metal temperature 2',\n",
    "    'LGB oil temperature', 'Penstock Flow', 'Turbine flow',\n",
    "    'UGB cooling water flow', 'LGB cooling water flow',\n",
    "    'Generator cooling water flow', 'Governor Penstock Pressure',\n",
    "    'Penstock pressure', 'Opening Wicked Gate', 'UGB Oil Contaminant',\n",
    "    'Gen Thrust Bearing Oil Contaminant']\n",
    "\n",
    "dataset_folder = 'data/CustomAWGN30ES15'\n",
    "df_train = pd.read_csv(os.path.join(dataset_folder, 'train.csv'))\n",
    "df_test = pd.read_csv(os.path.join(dataset_folder, 'test.csv'))\n",
    "df_train, df_test = df_train.values[:, 1:], df_test.values[:, 1:]\n",
    "_, min_a, max_a = normalize3(np.concatenate((df_train, df_test), axis=0))\n",
    "\n",
    "model_array = [\"Attention\", \"DTAAD\", \"MAD_GAN\", \"TranAD\", \"DAGMM\", \"USAD\"] # , CAE_M \"GDN\" MSCRED\n",
    "model_thr = {\"Attention\": 0, \"DTAAD\": 0, \"MAD_GAN\": 0, \"TranAD\": 0, \"DAGMM\": 0, \"USAD\": 0}\n",
    "\n",
    "for model_now in model_array:\n",
    "    with open(f'loss_fold/{model_now}.pickle', 'rb') as handle:\n",
    "        loss = pickle.load(handle)\n",
    "    model_thr[model_now] = [np.percentile(loss[:, index], 99) for index in range(len(feature_set))]\n",
    "\n",
    "measured_horizon = 60 * 3 * 1\n",
    "\n",
    "df_data_withtime = pd.read_pickle(\"/run/media/fourier/Data2/Pras/Vale/time-series-autoencoder/my_data_5thn_olah.pickle\")\n",
    "mask = (df_data_withtime['TimeStamp'] >= '2020-01-01 00:00:00')\n",
    "df_data_withtime = df_data_withtime.loc[mask]\n",
    "\n",
    "for column_name in df_data_withtime.columns:\n",
    "    if column_name != 'Load_Type' and column_name != 'TimeStamp':\n",
    "        df_data_withtime[column_name] = pd.to_numeric(df_data_withtime[column_name], downcast='float')\n",
    "        \n",
    "df_anomaly = pd.read_excel(\"/run/media/fourier/Data2/Pras/Vale/time-series-autoencoder/shutdown_list.xlsx\", 'Sheet2')\n",
    "df_anomaly['Start Time'] = pd.to_datetime(df_anomaly['Start Time'])\n",
    "df_anomaly['End Time'] = pd.to_datetime(df_anomaly['End Time'])\n",
    "df_anomaly_unplaned = df_anomaly.copy()\n",
    "\n",
    "mask = (df_anomaly_unplaned['Interal/External'] == 'Internal') & (df_anomaly_unplaned['Shutdown Type'] == 'Unplanned') & (df_anomaly_unplaned['Start Time'] >= '2020-01-01 00:00:00')\n",
    "df_anomaly_unplaned = df_anomaly_unplaned.loc[mask]\n",
    "df_anomaly_unplaned = df_anomaly_unplaned.reset_index(drop=True)\n",
    "df_anomaly_unplaned = df_anomaly_unplaned.drop(df_anomaly_unplaned.index[[2]])\n",
    "df_anomaly_unplaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/run/media/fourier/Data2/Pras/Vale/.env/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/run/media/fourier/Data2/Pras/Vale/.env/lib/python3.8/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "failure_index_list = 1\n",
    "index_before = 0\n",
    "\n",
    "threshold_percentage_all = {}\n",
    "end_date_filter = df_anomaly_unplaned.values[failure_index_list, 0] - timedelta(minutes=(100 * index_before) + 5)\n",
    "start_date_filter =  end_date_filter - timedelta(minutes=measured_horizon)\n",
    "\n",
    "mask = (df_data_withtime['TimeStamp'] > start_date_filter.strftime('%Y-%m-%d %H:%M:%S')) & (df_data_withtime['TimeStamp'] <= end_date_filter.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "df_sel = df_data_withtime.loc[mask]\n",
    "df_sel = df_sel.reset_index(drop=True)\n",
    "df_sel = wgn_pandas(df_sel, 30, alpha=0.15)\n",
    "\n",
    "df_timestamp = df_sel.iloc[:, 0]\n",
    "df_feature =  df_sel.iloc[:, 1:]\n",
    "df_feature = df_feature[feature_set]\n",
    "raw_active = df_feature['Active Power'].values\n",
    "\n",
    "df_feature, _, _ = normalize3(df_feature, min_a, max_a)\n",
    "df_feature = df_feature.astype(float)\n",
    "\n",
    "test_loader = DataLoader(df_feature.values, batch_size=df_feature.shape[0])\n",
    "testD = next(iter(test_loader))\n",
    "testO = testD\n",
    "\n",
    "for idx_model, model_now in enumerate(model_array):\n",
    "    model = load_model(model_now, testO.shape[1])\n",
    "    model.eval()\n",
    "    torch.zero_grad = True\n",
    "\n",
    "    if model.name in ['Attention', 'DAGMM', 'USAD', 'MSCRED', \n",
    "                        'CAE_M', 'GDN', 'MTAD_GAT', 'MAD_GAN', 'TranAD'] or 'DTAAD' in model.name:\n",
    "        testD_now = convert_to_windows(testD, model)\n",
    "\n",
    "    loss, y_pred = backprop(0, model, testD_now, testO, None, None, training=False)\n",
    "    if 'TranAD' or 'DTAAD' in model.name: testO_now = torch.roll(testO, 1, 0)\n",
    "\n",
    "    threshold_pass = {}\n",
    "    for idx_feat in range(loss.shape[-1]):\n",
    "        thres_bool = loss[:, idx_feat] > model_thr[model_now][idx_feat]\n",
    "        threshold_pass[feature_set[idx_feat]] = (thres_bool.sum() / thres_bool.shape[0]) * 100\n",
    "    \n",
    "    threshold_pass = dict(sorted(threshold_pass.items(), key=lambda item: item[1], reverse=True)[:5])\n",
    "    threshold_percentage_all[idx_model] = threshold_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UGB X displacement': {'count': 4, 'percentage': 394.44444444444446},\n",
       " 'LGB X displacement': {'count': 5, 'percentage': 390.0},\n",
       " 'LGB Y displacement': {'count': 4, 'percentage': 350.0},\n",
       " 'UGB Y displacement': {'count': 4, 'percentage': 116.66666666666667}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_feature = {}\n",
    "for modex_idx, values_pred in threshold_percentage_all.items():\n",
    "    for name_feat, percentage in values_pred.items():\n",
    "        if name_feat in counter_feature:\n",
    "            counter_feature[name_feat][\"count\"] = counter_feature[name_feat][\"count\"] + 1\n",
    "            counter_feature[name_feat][\"percentage\"] = counter_feature[name_feat][\"percentage\"] + percentage\n",
    "        else:\n",
    "            counter_feature[name_feat] = {\"count\": 1, \"percentage\": percentage}\n",
    "\n",
    "counter_feature_s1 = dict(sorted(counter_feature.items(), key=lambda item: item[1]['count'], reverse=True)[:4])\n",
    "counter_feature_s2 = dict(sorted(counter_feature_s1.items(), key=lambda item: item[1]['percentage'], reverse=True))\n",
    "counter_feature_s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_index_list = 1\n",
    "index_before = 0\n",
    "\n",
    "thr_array_fault = {}\n",
    "for failure_index_list in range(3):\n",
    "    threshold_percentage_all = {}\n",
    "    end_date_filter = df_anomaly_unplaned.values[failure_index_list, 0] - timedelta(minutes=(100 * index_before) + 5)\n",
    "    start_date_filter =  end_date_filter - timedelta(minutes=measured_horizon)\n",
    "\n",
    "    mask = (df_data_withtime['TimeStamp'] > start_date_filter.strftime('%Y-%m-%d %H:%M:%S')) & (df_data_withtime['TimeStamp'] <= end_date_filter.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    df_sel = df_data_withtime.loc[mask]\n",
    "    df_sel = df_sel.reset_index(drop=True)\n",
    "    df_sel = wgn_pandas(df_sel, 30, alpha=0.15)\n",
    "\n",
    "    df_timestamp = df_sel.iloc[:, 0]\n",
    "    df_feature =  df_sel.iloc[:, 1:]\n",
    "    df_feature = df_feature[feature_set]\n",
    "    raw_active = df_feature['Active Power'].values\n",
    "\n",
    "    df_feature, _, _ = normalize3(df_feature, min_a, max_a)\n",
    "    df_feature = df_feature.astype(float)\n",
    "\n",
    "    test_loader = DataLoader(df_feature.values, batch_size=df_feature.shape[0])\n",
    "    testD = next(iter(test_loader))\n",
    "    testO = testD\n",
    "\n",
    "    feature_num = 31\n",
    "\n",
    "    for idx_model, model_now in enumerate(model_array):\n",
    "        model, _, _, _, _ = load_model(model_now, testO.shape[1])\n",
    "        torch.zero_grad = True\n",
    "        model.eval()\n",
    "\n",
    "        if model.name in ['Attention', 'DAGMM', 'USAD', 'MSCRED', 'CAE_M', 'GDN', 'MTAD_GAT', 'MAD_GAN', 'TranAD'] or 'DTAAD' in model.name:\n",
    "            testD_now = convert_to_windows(testD, model)\n",
    "\n",
    "        loss, y_pred = backprop(0, model, testD_now, testO, None, None, training=False)\n",
    "        if 'TranAD' or 'DTAAD' in model.name: testO_now = torch.roll(testO, 1, 0)\n",
    "\n",
    "        threshold_pass = {}\n",
    "        for i in range(loss.shape[-1]):\n",
    "            index_plot = i + 1 + (idx_model * feature_num)\n",
    "            thres_bool = loss[:, i] > model_thr[model_now][i]\n",
    "            threshold_pass[feature_set[i]] = (thres_bool.sum() / thres_bool.shape[0]) * 100\n",
    "        \n",
    "        threshold_pass = dict(sorted(threshold_pass.items(), key=lambda item: item[1], reverse=True)[:5])\n",
    "        threshold_percentage_all[model_now] = threshold_pass\n",
    "\n",
    "    thr_array_fault[df_anomaly_unplaned.values[failure_index_list, 4]] = threshold_percentage_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
